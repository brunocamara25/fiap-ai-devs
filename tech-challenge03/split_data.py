#!/usr/bin/env python3
"""
Script para dividir dados de fine-tuning em conjuntos de treinamento e valida√ß√£o.
"""

import argparse
import json
import random
from typing import Any, Dict, List


def split_fine_tuning_data(input_file: str, train_ratio: float = 0.8, shuffle: bool = True):
    """
    Divide dados de fine-tuning em conjuntos de treinamento e valida√ß√£o.
    
    Args:
        input_file: Arquivo JSONL gerado pelo convert_for_fine_tuning.py
        train_ratio: Propor√ß√£o dos dados para treinamento (0.8 = 80%)
        shuffle: Se deve embaralhar os dados antes da divis√£o
    """
    
    # L√™ todos os dados
    print(f"üìñ Lendo dados de {input_file}...")
    data = []
    with open(input_file, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if line:
                data.append(json.loads(line))
    
    print(f"Total de exemplos carregados: {len(data)}")
    
    # Embaralha se solicitado
    if shuffle:
        random.shuffle(data)
        print("‚úÖ Dados embaralhados")
    
    # Calcula divis√£o
    total_examples = len(data)
    train_size = int(total_examples * train_ratio)
    val_size = total_examples - train_size
    
    # Divide os dados
    train_data = data[:train_size]
    val_data = data[train_size:]
    
    # Gera nomes de arquivo baseados no arquivo de entrada
    base_name = input_file.replace('.jsonl', '')
    train_file = f"{base_name}_train.jsonl"
    val_file = f"{base_name}_validation.jsonl"
    
    # Salva dados de treinamento
    with open(train_file, 'w', encoding='utf-8') as f:
        for item in train_data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
    
    # Salva dados de valida√ß√£o
    with open(val_file, 'w', encoding='utf-8') as f:
        for item in val_data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
    
    # Imprime estat√≠sticas
    print("\nüìä Divis√£o dos Dados:")
    print("=" * 40)
    print(f"Total de exemplos: {total_examples}")
    print(f"Treinamento: {train_size} exemplos ({train_ratio*100:.1f}%)")
    print(f"Valida√ß√£o: {val_size} exemplos ({(1-train_ratio)*100:.1f}%)")
    print()
    print(f"üìÅ Arquivos criados:")
    print(f"   Treinamento: {train_file}")
    print(f"   Valida√ß√£o: {val_file}")
    
    return train_file, val_file


def main():
    parser = argparse.ArgumentParser(description="Divide dados de fine-tuning em treinamento e valida√ß√£o")
    parser.add_argument('input_file', help='Arquivo JSONL gerado pelo convert_for_fine_tuning.py')
    parser.add_argument('--train_ratio', type=float, default=0.8, 
                       help='Propor√ß√£o para treinamento (padr√£o: 0.8 = 80%%)')
    parser.add_argument('--no-shuffle', action='store_true',
                       help='N√£o embaralhar os dados antes da divis√£o')
    
    args = parser.parse_args()
    
    # Valida argumentos
    if not 0.1 <= args.train_ratio <= 0.9:
        print("‚ùå Erro: train_ratio deve estar entre 0.1 e 0.9")
        return
    
    try:
        train_file, val_file = split_fine_tuning_data(
            args.input_file, 
            args.train_ratio, 
            shuffle=not args.no_shuffle
        )
        
        print("\n‚úÖ Divis√£o conclu√≠da com sucesso!")
        print("\nüöÄ Pr√≥ximos passos:")
        print(f"   openai api fine_tuning.jobs.create --training-file {train_file} --validation-file {val_file} --model gpt-3.5-turbo")
        
    except FileNotFoundError:
        print(f"‚ùå Erro: Arquivo '{args.input_file}' n√£o encontrado")
    except Exception as e:
        print(f"‚ùå Erro durante a divis√£o: {e}")


if __name__ == "__main__":
    main() 