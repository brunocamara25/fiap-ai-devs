# ğŸ§  Fine-Tuning com Unsloth + TinyLlama no Dataset AmazonTitles-1.3MM

## ğŸ“˜ VisÃ£o Geral

Este projeto foi desenvolvido como parte de um **Tech Challenge**, com o objetivo de realizar **fine-tuning de um modelo LLM** usando o dataset **AmazonTitles-1.3MM**, contendo tÃ­tulos e descriÃ§Ãµes de produtos. O modelo aprende a gerar descriÃ§Ãµes de produtos com base apenas em seus tÃ­tulos.

Utilizamos o modelo `unsloth/tinyllama-bnb-4bit` pela leveza e performance, com **LoRA** e **4-bit quantization**, utilizando **Google Colab** com GPU.

---

## ğŸ§¾ SumÃ¡rio

* [Modelo Utilizado](#modelo-utilizado)
* [Dataset](#dataset)
* [Fluxo de Treinamento](#fluxo-de-treinamento)
* [Exemplos](#exemplos)
* [Resultados](#resultados)
* [ConclusÃ£o](#conclusÃ£o)

---

## ğŸ’¡ Modelo Utilizado

* **Modelo:** `unsloth/tinyllama-bnb-4bit`
* **Framework:** [Unsloth](https://github.com/unslothai/unsloth)
* **TÃ©cnica:** LoRA
* **Formato:** 4-bit quantization (bnb)

---

## ğŸ“‚ Dataset

Utilizado o dataset **AmazonTitles-1.3MM** com campos:

```json
{
  "uid": "0000032069", 
  "title": "Adult Ballet Tutu Cheetah Pink", 
  "content": "..."
}
```

ApÃ³s o prÃ©-processamento, o dataset foi transformado no formato:

```json
{
  "instruction": "Responda com a descriÃ§Ã£o do produto baseado no tÃ­tulo fornecido.",
  "input": "Adult Ballet Tutu Cheetah Pink",
  "output": "Uma descriÃ§Ã£o relevante do produto."
}
```

---

## âš™ï¸ Fluxo de Treinamento

### ğŸ“¦ 1. Montagem do Google Drive

```python
from google.colab import drive
drive.mount('/content/drive')
```

### ğŸ“¥ 2. InstalaÃ§Ã£o de DependÃªncias

```python
!pip install "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git"
!pip install --no-deps xformers "trl<0.9.0" peft accelerate bitsandbytes
!pip install transformers datasets trl
```

### ğŸ”„ 3. PreparaÃ§Ã£o dos Dados

```python
def prepare_data(input_path, output_path):
    ...
    # Gera arquivos train_data.jsonl e test_data.jsonl
```

---

### ğŸ§  4. Carregamento do Modelo

```python
from unsloth import FastLanguageModel

model, tokenizer = FastLanguageModel.from_pretrained(
    model_name="unsloth/tinyllama-bnb-4bit",
    max_seq_length=1024,
    dtype=None,
    load_in_4bit=True,
)
```

### ğŸ”§ 5. AplicaÃ§Ã£o do LoRA

```python
model = FastLanguageModel.get_peft_model(
    model,
    r=16,
    lora_alpha=16,
    lora_dropout=0.1,
    bias="none",
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj"]
)
```

### âœ… 6. Preparar para Treinamento

```python
model = FastLanguageModel.for_training(model)
```

---

### ğŸ” 7. Teste Antes do Fine-Tuning

```python
def gerar_resposta_pretreino(produto):
    ...
print(gerar_resposta_pretreino("Mog's Family of Cats"))
```

---

### ğŸ“š 8. Carregamento do Dataset

```python
from datasets import load_dataset

dataset = load_dataset("json", data_files=".../train_data.jsonl", split="train")
dataset = dataset.shuffle(seed=42).select(range(50000))
```

---

### ğŸš€ 9. Treinamento com `SFTTrainer`

```python
from trl import SFTTrainer

trainer = SFTTrainer(
    model=model,
    train_dataset=dataset,
    dataset_text_field="output",
    tokenizer=tokenizer,
    args=TrainingArguments(
        output_dir="model",
        per_device_train_batch_size=4,
        num_train_epochs=1,
        fp16=True,
        ...
    )
)
trainer.train()
```

---

### ğŸ’¾ 10. Salvamento do Modelo

```python
model.save_pretrained("/content/drive/MyDrive/TechChallenge3/model/")
tokenizer.save_pretrained("/content/drive/MyDrive/TechChallenge3/model/")
```

---

## ğŸ§ª Exemplos

ApÃ³s o fine-tuning:

```python
def gerar_resposta(produto):
    prompt = f"### InstruÃ§Ã£o:\nDescreva o seguinte produto:\n### Produto:\n{produto}\n### Resposta:"
    ...
```

### ğŸ” Resultados:

```python
gerar_resposta("Mog's Family of Cats")
gerar_resposta("Why Don't They Just Quit? DVD Roundtable Discussion")
```

---

## ğŸ“Š Resultados

| MÃ©trica               | Antes do Treino | ApÃ³s o Treino |
| --------------------- | --------------- | ------------- |
| CoerÃªncia             | Baixa           | Alta          |
| RelevÃ¢ncia Contextual | Fraca           | Boa           |
| AderÃªncia Ã  InstruÃ§Ã£o | Irregular       | Consistente   |

---

## âœ… ConclusÃ£o

* O uso do **TinyLlama com Unsloth e LoRA** permitiu treinar um modelo leve e eficaz diretamente no **Google Colab**.
* O modelo conseguiu **aprender padrÃµes do dataset** e responder com descriÃ§Ãµes contextualizadas de produtos.
* Ã‰ possÃ­vel expandir o projeto com mais Ã©pocas, validaÃ§Ã£o e mÃ©tricas automÃ¡ticas (BLEU, ROUGE, etc).

---

## ğŸ“ Estrutura de Arquivos

```
TechChallenge3/
â”œâ”€â”€ trn.json
â”œâ”€â”€ tst.json
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ train_data.jsonl
â”‚   â””â”€â”€ test_data.jsonl
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ adapter_model.bin
â”‚   â””â”€â”€ tokenizer_config.json
```
