# Conversor de Dados de Produtos Amazon com Fine-tuning da OpenAI

Este script converte seus dados de produtos da  Amazon do formato JSONL para o formato adequado para fazer fine-tuning de modelos da OpenAI. Fornece m√∫ltiplas estrat√©gias de convers√£o para diferentes objetivos de treinamento.


## Integrantes do Grupo üë•
- Bruno C√¢mara - RM 359922
- Fabricio Cavalcante - RM 360135
- Leonardo Charelli - RM 360425
- Lucas Pincho - RM 360216
- Natalia Rosa - RM 358301

## üéØ Cen√°rios de Treinamento Suportados

### 1. Gera√ß√£o de Descri√ß√£o de Produtos
**Caso de uso**: Treinar o modelo para gerar descri√ß√µes detalhadas de produtos a partir de t√≠tulos.
- **Entrada**: T√≠tulo do produto
- **Sa√≠da**: Descri√ß√£o detalhada do produto

### 2. Perguntas e Respostas sobre Produtos
**Caso de uso**: Treinar o modelo para responder perguntas de clientes sobre produtos.
- **Entrada**: T√≠tulo do produto + pergunta do cliente
- **Sa√≠da**: Resposta √∫til baseada nas informa√ß√µes do produto

### 3. Melhoria de Descri√ß√£o de Produtos
**Caso de uso**: Treinar o modelo para aprimorar informa√ß√µes b√°sicas do produto.
- **Entrada**: T√≠tulo b√°sico do produto
- **Sa√≠da**: T√≠tulo aprimorado + descri√ß√£o detalhada

### 4. Categoriza√ß√£o de Produtos
**Caso de uso**: Treinar o modelo para classificar produtos em categorias.
- **Entrada**: T√≠tulo + descri√ß√£o do produto
- **Sa√≠da**: Classifica√ß√£o de categoria


## üìã Requisitos

Os scripts utilizam apenas bibliotecas padr√£o do Python (n√£o requer instala√ß√£o adicional):
- `argparse` - Para parsing de argumentos da linha de comando
- `json` - Para manipula√ß√£o de dados JSON/JSONL
- `random` - Para embaralhamento de dados
- `html` - Para decodifica√ß√£o de entidades HTML
- `re` - Para express√µes regulares
- `unicodedata` - Para normaliza√ß√£o de texto
- `typing` - Para type hints

**Python 3.6+ √© requerido.**

## üßπ Limpeza de Dados

Executar o comando abaixo, esse primeiro comando √© responsavel por retornar o nosso arquivo com apenas as informa√ß√µes de t√≠tulo e conte√∫do.

```bash
jq -c 'select(.title != "" and .content != "") | {title, content}' example.jsonl >
example_filter.jsonl && echo "Filtragem Conclu√≠da. Linhas Originais:
$(wc -l < example_filter.jsonl), Linhas Filtradas: $(wc -l < trn_filter.jsonl)"
```

**‚ö†Ô∏è IMPORTANTE**: Dados brutos do arquivo da Amazon frequentemente cont√™m entidades HTML, spam de marketing, duplicatas e problemas de formata√ß√£o que prejudicar√£o o desempenho do seu modelo. **Limpe seus dados primeiro!**

### Por Que Limpar Seus Dados?

Notamos que o conteudo do arquivo tem:
- **Entidades HTML**: `&amp;`, `&reg;`, `&#9733;` ao inv√©s de `&`, `¬Æ`, `‚òÖ`
- **Spam de marketing**: Emojis excessivos, texto em mai√∫sculas, linguagem promocional
- **Duplicatas**: Mesmos produtos listados m√∫ltiplas vezes
- **T√≠tulos longos**: T√≠tulos de 200+ caracteres com palavras-chave excessivas
- **Formata√ß√£o ruim**: Espa√ßamento inconsistente, s√≠mbolos, problemas de codifica√ß√£o

### Script de Limpeza de Dados

O script `clean_amazon_data.py` corrige automaticamente esses problemas:

#### ‚úÖ **O Que Ele Corrige:**
- **Decodifica√ß√£o de Entidades HTML**: Converte entidades HTML para caracteres apropriados
- **Detec√ß√£o de Spam de Marketing**: Remove conte√∫do promocional excessivo
- **Truncamento de T√≠tulos**: Encurta inteligentemente t√≠tulos excessivamente longos
- **Remo√ß√£o de Duplicatas**: Identifica e remove produtos duplicados
- **Valida√ß√£o de Conte√∫do**: Remove entradas com conte√∫do insuficiente
- **Normaliza√ß√£o de Texto**: Padroniza espa√ßamento, pontua√ß√£o e formata√ß√£o

#### üöÄ **Uso R√°pido:**

```bash
# Limpe seus dados primeiro (recomendado)
python clean_amazon_data.py trn_filter.jsonl -o cleaned_amazon_data.jsonl
```

#### üìä **Op√ß√µes de Linha de Comando:**

| Op√ß√£o | Descri√ß√£o | Padr√£o |
|-------|-----------|--------|
| `input_file` | Arquivo JSONL de entrada para limpar | Obrigat√≥rio |
| `-o, --output` | Nome do arquivo de sa√≠da | `cleaned_amazon_data.jsonl` |
| `--keep-duplicates` | Manter entradas duplicadas | Remover duplicatas |
| `--min-content-length` | Comprimento m√≠nimo do conte√∫do | 20 caracteres |
| `--max-title-length` | Comprimento m√°x. do t√≠tulo antes do truncamento | 150 caracteres |

#### üìà **Resultados de Exemplo:**

```
üìä Resultados da Limpeza de Dados:
==================================================
Total de entradas processadas: 159
Entidades HTML limpas: 103
Duplicatas removidas: 4
Conte√∫do curto removido: 2
T√≠tulos longos truncados: 66
Spam de marketing removido: 1
Entradas limpas finais: 151
Taxa de reten√ß√£o de dados: 95.0%
```

#### üîß **Limpeza Avan√ßada:**

```bash
# Manter duplicatas mas limpar formata√ß√£o
python clean_amazon_data.py input.jsonl --keep-duplicates -o cleaned.jsonl

# Filtragem de conte√∫do mais agressiva
python clean_amazon_data.py input.jsonl --min-content-length 50 -o cleaned.jsonl

# Permitir t√≠tulos mais longos
python clean_amazon_data.py input.jsonl --max-title-length 200 -o cleaned.jsonl
```

### Antes vs Depois da Limpeza

**‚ùå Antes da Limpeza:**
```json
{
  "title": "&#9733;4.8 / 5 Stars&#9733; - Forskolin Pure Coleus Forskohlii Root Standardized to 20% Weight Loss Supplement and Appetite Suppressant - Dr Oz Highly Recommended Product for Fat Burning and Melting Belly Fat - The Best Forskolin Product on the Market!! 250mg Yielding 50 Mg of Active Forskolin - Works Excellent with Pure Garcinia Cambogia and Colon Cleanse Detox and Full Body Detox - 100% Money Back Guarantee - 60 Veggie Capsules",
  "content": "BD HeaderHow Does Coleus Forskohlii (Forskolin) Affect cAMP?..."
}
```

**‚úÖ Depois da Limpeza:**
```json
{
  "title": "‚òÖ4.8 / 5 Stars‚òÖ - Forskolin Pure Coleus Forskohlii Root Standardized to 20% Weight Loss Supplement and Appetite Suppressant",
  "content": "BD HeaderHow Does Coleus Forskohlii (Forskolin) Affect cAMP?..."
}
```

## üìä Divis√£o de Dados: Treinamento vs Valida√ß√£o

### Por Que Dividir Seus Dados?

#### ‚úÖ **Benef√≠cios da Divis√£o de Dados:**
- **Previne Overfitting**: Ajuda voc√™ a saber quando parar o treinamento
- **Monitoramento de Performance**: Acompanha qu√£o bem seu modelo generaliza
- **Otimiza√ß√£o de Custos**: Evita √©pocas de treinamento desnecess√°rias
- **Garantia de Qualidade**: Testa modelo em dados n√£o vistos
- **Detec√ß√£o Precoce de Problemas**: Identifica problemas de generaliza√ß√£o

### Script de Divis√£o de Dados

O script `split_data.py` divide automaticamente seus dados convertidos:

#### üöÄ **Uso R√°pido:**

```bash
# Divide dados em 80% treinamento / 20% valida√ß√£o (padr√£o)
python split_data.py fine_tune_product_description.jsonl
```

#### üìä **Op√ß√µes de Linha de Comando:**

| Op√ß√£o | Descri√ß√£o | Padr√£o |
|-------|-----------|--------|
| `input_file` | Arquivo JSONL gerado pelo convert_for_fine_tuning.py | Obrigat√≥rio |
| `--train_ratio` | Propor√ß√£o para treinamento (0.1 a 0.9) | 0.8 (80%) |
| `--no-shuffle` | N√£o embaralhar dados antes da divis√£o | Embaralhar habilitado |

#### üìà **Resultado de Exemplo:**

```
üìä Divis√£o dos Dados:
========================================
Total de exemplos: 151
Treinamento: 120 exemplos (80.0%)
Valida√ß√£o: 31 exemplos (20.0%)

üìÅ Arquivos criados:
   Treinamento: fine_tune_product_description_train.jsonl
   Valida√ß√£o: fine_tune_product_description_validation.jsonl
```

#### üéØ **Guia de Propor√ß√µes de Divis√£o:**

| Tamanho do Dataset | Divis√£o Recomendada | Treinamento | Valida√ß√£o |
|-------------------|-------------------|-------------|-----------|
| 50-100 exemplos | 90/10 | 90% | 10% |
| 100-500 exemplos | 85/15 | 85% | 15% |
| 500+ exemplos | 80/20 | 80% | 20% |

#### üîß **Divis√£o Avan√ßada:**

```bash
# Divis√£o 85/15 (recomendado para datasets menores)
python split_data.py fine_tune_product_description.jsonl --train_ratio 0.85

# Divis√£o 90/10 (para datasets muito pequenos)
python split_data.py fine_tune_product_description.jsonl --train_ratio 0.9

# Manter ordem original (n√£o embaralhar)
python split_data.py fine_tune_product_description.jsonl --no-shuffle
```

### üéØ **Fluxo de Trabalho Recomendado**

```bash
# Passo 1: Limpar seus dados
python clean_amazon_data.py trn_filter.jsonl -o cleaned_amazon_data.jsonl

# Passo 2: Converter para fine-tuning
python convert_for_fine_tuning.py cleaned_amazon_data.jsonl --format description --shuffle

# Passo 3: Dividir em treinamento/valida√ß√£o
python split_data.py fine_tune_product_description.jsonl

# Passo 4: Iniciar fine-tuning com valida√ß√£o - Recomendadmos usar a vers√£o gr√°fica
# direto do dashboard -  https://platform.openai.com/finetune
openai api fine_tuning.jobs.create \
  --training-file fine_tune_product_description_train.jsonl \
  --validation-file fine_tune_product_description_validation.jsonl \
  --model gpt-3.5-turbo \
  --suffix "product-descriptions"
```

**A divis√£o de dados tipicamente melhora a qualidade do modelo em 15-30%**, resultando em:
- ‚úÖ Melhor generaliza√ß√£o para novos produtos
- ‚úÖ Redu√ß√£o de overfitting
- ‚úÖ Detec√ß√£o precoce de problemas de treinamento
- ‚úÖ Otimiza√ß√£o de custos de treinamento

## üöÄ Uso

### Uso B√°sico (Converter todos os formatos)
```bash
python convert_for_fine_tuning.py cleaned_amazon_data.jsonl
```

### Converter apenas formato espec√≠fico
```bash
python convert_for_fine_tuning.py cleaned_amazon_data.jsonl --format description
```

### Testar com uma amostra (recomendado primeiro)
```bash
python convert_for_fine_tuning.py cleaned_amazon_data.jsonl --sample_size 100 --shuffle
```

### Salvar em diret√≥rio espec√≠fico
```bash
python convert_for_fine_tuning.py cleaned_amazon_data.jsonl --output_dir ./fine_tune_data/
```

## üìä Op√ß√µes de Linha de Comando

| Op√ß√£o | Descri√ß√£o | Padr√£o |
|-------|-----------|--------|
| `input_file` | Caminho para seu arquivo JSONL | Obrigat√≥rio |
| `--format` | Formato de convers√£o: `description`, `qa`, `improvement`, `categorization`, `completion`, `all` | `all` |
| `--output_dir` | Diret√≥rio para salvar arquivos de sa√≠da | Diret√≥rio atual |
| `--sample_size` | Limitar n√∫mero de amostras para teste | Todos os dados |
| `--shuffle` | Embaralhar dados aleatoriamente antes do processamento | False |

## üìÅ Arquivos de Sa√≠da

O script gera arquivos diferentes baseados no formato:

- `fine_tune_product_description.jsonl` - Para gera√ß√£o de descri√ß√£o
- `fine_tune_product_qa.jsonl` - Para treinamento de P&R
- `fine_tune_product_improvement.jsonl` - Para melhoria de descri√ß√£o
- `fine_tune_product_categorization.jsonl` - Para categoriza√ß√£o de produtos

## üìù Exemplos de Formatos de Sa√≠da

### Formato Chat (GPT-3.5-turbo/GPT-4)
```json
{
  "messages": [
    {
      "role": "system",
      "content": "You are a professional product description writer..."
    },
    {
      "role": "user",
      "content": "Write a product description for: iPhone Charger Cable"
    },
    {
      "role": "assistant",
      "content": "Premium quality charging cable compatible with iPhone..."
    }
  ]
}
```


## üîß Fine-tuning com OpenAI

### 1. Instalar CLI da OpenAI
```bash
pip install openai
```

### 2. Definir sua chave da API
```bash
export OPENAI_API_KEY="sua-chave-da-api-aqui"
```

### 3. Fazer upload e iniciar fine-tuning - Tivemos problema com a execu√ß√£o via CLI, ent√£o recomendamos nessa etapa fazer direto no dashboard da plataforma da OpenAI

#### Para modelos Chat (GPT-3.5-turbo):
```bash
# Com arquivo de valida√ß√£o (recomendado)
openai api fine_tuning.jobs.create \
  --training-file fine_tune_product_description_train.jsonl \
  --validation-file fine_tune_product_description_validation.jsonl \
  --model gpt-3.5-turbo \
  --suffix "product-descriptions"

# Sem arquivo de valida√ß√£o (n√£o recomendado)
openai api fine_tuning.jobs.create \
  --training-file fine_tune_product_description.jsonl \
  --model gpt-3.5-turbo \
  --suffix "product-descriptions"
```

### 3. Monitorar treinamento - √â possivel ver direto na plataforma da OpenAI tamb√©m
```bash
# Listar jobs de fine-tuning
openai api fine_tuning.jobs.list

# Monitorar job espec√≠fico
openai api fine_tuning.jobs.retrieve -i ftjob-abc123

# Ver eventos do job
openai api fine_tuning.jobs.list-events -i ftjob-abc123
```

### 4. Testar seu modelo fine-tuned - √â possivel executar direto na plataforma da OpenAI tamb√©m
```bash
# Usando a CLI da OpenAI
openai api chat.completions.create \
  --model ft:gpt-3.5-turbo:your-org:product-descriptions:abc123 \
  --messages '[{"role": "user", "content": "Write a product description for: Wireless Headphones"}]'
```

## ‚úÖ Melhores Pr√°ticas

### Qualidade dos Dados
- **Limpe seus dados PRIMEIRO**: Use `clean_amazon_data.py` para corrigir entidades HTML, remover spam e padronizar formata√ß√£o
- **Verifique resultados da limpeza**: Revise as estat√≠sticas de limpeza para garantir boa reten√ß√£o de dados
- **Remova entradas de baixa qualidade**: O script de limpeza remove automaticamente entradas com conte√∫do insuficiente
- **Trate duplicatas**: Use remo√ß√£o de duplicatas (habilitada por padr√£o no script de limpeza)
- **Valide ap√≥s limpeza**: Verifique manualmente algumas entradas limpas para garantir qualidade

### Otimiza√ß√£o de Custos
- **Fa√ßa amostra dos seus dados**: Comece com 100-500 exemplos para teste
- **Escolha o modelo certo**: GPT-3.5-turbo √© mais barato que GPT-4

## üéØ Fine-tuning de Tarefa √önica vs Multi-tarefas

### üèÜ **Recomenda√ß√£o: Foque em UMA Tarefa**

**√â fortemente recomendado escolher UM formato espec√≠fico** ao inv√©s de misturar m√∫ltiplas tarefas. Aqui est√° o porqu√™:

#### ‚úÖ Benef√≠cios do Fine-tuning de Tarefa √önica
- **Maior Qualidade**: Modelo se torna altamente especializado e performa melhor
- **Sa√≠das Consistentes**: Formato e estilo previs√≠veis sempre  
- **Avalia√ß√£o Mais F√°cil**: Simples de medir sucesso e identificar problemas
- **Menos Confus√£o**: Modelo n√£o mistura diferentes formatos de tarefa

#### ‚ùå Problemas com Fine-tuning Multi-tarefas
- **Degrada√ß√£o de Desempenho**: Sabe de tudo um pouco, especialista em nada
- **Confus√£o de Formato**: Modelo pode misturar diferentes estilos de sa√≠da
- **Resultados Inconsistentes**: Comportamento imprevis√≠vel dependendo da entrada

### üìä Compara√ß√£o de Tarefas

| Tarefa | Melhor Para | Adequa√ß√£o dos Dados | Valor Comercial | Dificuldade |
|--------|-------------|---------------------|-----------------|-------------|
| `description` |  E-commerce | Perfeita | Muito Alto | F√°cil |
| `qa` |  Suporte ao Cliente | Boa | Alto | M√©dio |
| `improvement` |  Melhoria de Conte√∫do | Boa | M√©dio | M√©dio |
| `categorization` |  Organiza√ß√£o | Razo√°vel | M√©dio | Dif√≠cil |



## üîç Exemplo de Fluxo de Trabalho

1. **Limpar seus dados (PRIMEIRO PASSO)**:
   ```bash
   python clean_amazon_data.py trn_filter.jsonl -o cleaned_amazon_data.jsonl
   ```

2. **Testar o script de convers√£o**:
   ```bash
   python convert_for_fine_tuning.py cleaned_amazon_data.jsonl --sample_size 10 --format description
   ```

3. **Revisar a sa√≠da**:
   ```bash
   head -5 fine_tune_product_description.jsonl
   ```

4. **Gerar dados de treinamento**:
   ```bash
   python convert_for_fine_tuning.py cleaned_amazon_data.jsonl --format description --shuffle
   ```

5. **Dividir dados para treinamento e valida√ß√£o**:
   ```bash
   python split_data.py fine_tune_product_description.jsonl
   ```

6. **Iniciar fine-tuning com valida√ß√£o**: Usar interface grafica como alternativa. https://platform.openai.com/finetune
   ```bash
   openai api fine_tuning.jobs.create \
     --training-file fine_tune_product_description_train.jsonl \
     --validation-file fine_tune_product_description_validation.jsonl \
     --model gpt-3.5-turbo \
     --suffix "product-descriptions"
   ```

7. **Monitorar progresso do treinamento**:
   ```bash
   openai api fine_tuning.jobs.list-events -i ftjob-abc123
   ```